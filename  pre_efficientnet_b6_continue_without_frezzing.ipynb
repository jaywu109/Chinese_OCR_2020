{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae89071",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "aec1d41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "import torch \n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "69f2cba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "from __future__ import print_function\n",
    "from pytorch_lightning.metrics.functional import accuracy\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageFont\n",
    "from PIL import ImageDraw\n",
    "import pickle\n",
    "import argparse\n",
    "from argparse import RawTextHelpFormatter\n",
    "import fnmatch\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import shutil\n",
    "import traceback\n",
    "import copy\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "import random \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import os\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor, ModelCheckpoint\n",
    "\n",
    "from torch.nn import functional as F\n",
    "import torchmetrics\n",
    "\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pl_bolts.callbacks import PrintTableMetricsCallback\n",
    "\n",
    "\n",
    "import math\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c1734220",
   "metadata": {},
   "outputs": [],
   "source": [
    "class pre_efficientnet_b6_ap(pl.LightningModule):\n",
    "    def __init__(self, learning_rate, batch_size):\n",
    "        \n",
    "        super(pre_efficientnet_b6_ap, self).__init__()\n",
    "        \n",
    "        self.lr = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "\n",
    "        backbone = timm.create_model('tf_efficientnet_b6_ap', pretrained=True)\n",
    "        layers = list(backbone.children())\n",
    "        num_filters =layers[-1].in_features\n",
    "        \n",
    "        layer1 = layers[0]\n",
    "        layer2 = layers[1:-5]\n",
    "        layer3 = layers[-5:-1]\n",
    "        \n",
    "        self.seq1 = nn.Sequential(layer1)\n",
    "        self.seq2 = nn.Sequential(*layer2)\n",
    "        self.seq3 = nn.Sequential(*layer3)\n",
    "\n",
    "        num_target_classes = 800\n",
    "        self.classifier = nn.Linear(num_filters, num_target_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.seq1(x)\n",
    "        self.seq2.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            x = self.seq2(x)\n",
    "            \n",
    "        x = self.seq3(x).flatten(1)   \n",
    "        x = self.classifier(x)\n",
    "\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4529cf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class pre_efficientnet_b6_ap_v2(pl.LightningModule):\n",
    "    def __init__(self, learning_rate, batch_size):\n",
    "        \n",
    "        super(pre_efficientnet_b6_ap_v2, self).__init__()\n",
    "        \n",
    "        self.lr = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "\n",
    "        layers = list(pre_efficientnet_b6_ap.load_from_checkpoint('efficientnet_b6_ap_epoch=23-val_loss=8.2352.ckpt').children())\n",
    "        \n",
    "        layer1 = [layers[0]] + [layers[1][:2]] + [layers[1][2][0][0]]\n",
    "        layer2 = [layers[1][2][0][1:]] + [layers[1][2][1:-1]] + [layers[1][2][-1][:-1]]\n",
    "        layer3 = [layers[1][2][-1][-1]] + [layers[2]]\n",
    "        \n",
    "        self.seq1 = nn.Sequential(*layer1)\n",
    "        self.seq2 = nn.Sequential(*layer2)\n",
    "        self.seq3 = nn.Sequential(*layer3)\n",
    "\n",
    "        self.classifier = layers[-1]\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        \n",
    "        self.seq1.eval()\n",
    "        self.seq2.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            x = self.seq1(x)\n",
    "            x = self.seq2(x)\n",
    "            \n",
    "        x = self.seq3(x).flatten(1)   \n",
    "        x = self.classifier(x)\n",
    "\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        lr_scheduler = {'scheduler': torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma = 0.95),\n",
    "                        'name': 'expo_lr'}\n",
    "        return [optimizer], [lr_scheduler]\n",
    "    \n",
    "    def training_step(self,batch,batch_idx):\n",
    "        \n",
    "        x, y = batch\n",
    "        logits = self.forward(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = accuracy(preds, y)\n",
    "\n",
    "        \n",
    "        self.log('train_loss',loss, prog_bar=True , on_step=True, on_epoch=True)\n",
    "        self.log('train_acc', acc, prog_bar=True , on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def validation_step(self,batch,batch_idx):\n",
    "        \n",
    "        x, y = batch\n",
    "        logits = self.forward(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = accuracy(preds, y)\n",
    "        \n",
    "        self.log('val_loss', loss, prog_bar=True , on_step=False, on_epoch=True)\n",
    "        self.log('val_acc', acc, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        return loss, acc\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "\n",
    "        train_dir = 'C:/Users/bbb50/Desktop/Python/OCR/t_brain_new_gray_augmented/train'\n",
    "    \n",
    "        data_transform = transforms.Compose([\n",
    "                                    transforms.Resize(size = (224, 224)),\n",
    "                                    transforms.Grayscale(num_output_channels=3),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "        ds = ImageFolder(train_dir, transform=data_transform)\n",
    "\n",
    "        return DataLoader(ds, batch_size=self.batch_size, shuffle=True)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        val_dir = 'C:/Users/bbb50/Desktop/Python/OCR/t_brain_new_gray_augmented/val'\n",
    "        data_transform = transforms.Compose([\n",
    "                                    transforms.Resize(size = (224, 224)),\n",
    "                                    transforms.Grayscale(num_output_channels=3),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "        ds = ImageFolder(val_dir, transform=data_transform)\n",
    "\n",
    "        return DataLoader(ds, batch_size=self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "977cd63b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model =  pre_efficientnet_b6_ap_v2(0.075, 64)\n",
    "\n",
    "lr_logger = LearningRateMonitor()\n",
    "\n",
    "logger = TensorBoardLogger(\"tb_pre_efficientnet_b6_ap_v2\", name=\"pre_efficientnet_b6_ap_v2\")\n",
    "\n",
    "early_stopping = EarlyStopping('val_loss', mode='min', patience=5)\n",
    "\n",
    "model_path = 'C:/Users/bbb50/Desktop/Python/OCR/model_path/pre_efficientnet_b6_ap_v2'\n",
    "checkpoint_callback = ModelCheckpoint(dirpath=model_path, filename= 'efficientnet_b6_ap_v2_{epoch}-{val_loss:.4f}',\n",
    "                                      monitor='val_loss', mode='min', save_top_k=5)\n",
    "\n",
    "trainer = pl.Trainer( gpus=1, limit_train_batches=0.25 ,max_epochs=100, callbacks=[lr_logger, early_stopping, checkpoint_callback], logger=logger,\n",
    "       ) #gpus=1\n",
    "\n",
    "# ,limit_train_batches=0.25, limit_val_batches=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fa631b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type       | Params\n",
      "------------------------------------------\n",
      "0 | seq1       | Sequential | 5.7 K \n",
      "1 | seq2       | Sequential | 34.4 M\n",
      "2 | seq3       | Sequential | 6.4 M \n",
      "3 | classifier | Linear     | 1.8 M \n",
      "------------------------------------------\n",
      "42.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "42.6 M    Total params\n",
      "170.319   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3f01f9bc7e340f9b154393df8889e78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c956b67e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
