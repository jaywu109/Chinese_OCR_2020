{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b910c9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "from __future__ import print_function\n",
    "from pytorch_lightning.metrics.functional import accuracy\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageFont\n",
    "from PIL import ImageDraw\n",
    "import pickle\n",
    "import argparse\n",
    "from argparse import RawTextHelpFormatter\n",
    "import fnmatch\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import shutil\n",
    "import traceback\n",
    "import copy\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "import random \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import os\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor, ModelCheckpoint\n",
    "\n",
    "from torch.nn import functional as F\n",
    "import torchmetrics\n",
    "\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pl_bolts.callbacks import PrintTableMetricsCallback\n",
    "\n",
    "\n",
    "import math\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "\n",
    "import timm\n",
    "\n",
    "from scipy.sparse import coo_matrix, csr_matrix, lil_matrix, vstack, hstack\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bbbe0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class pre_resnest50(pl.LightningModule):\n",
    "    def __init__(self, learning_rate, batch_size):\n",
    "        \n",
    "        super(pre_resnest50, self).__init__()\n",
    "        \n",
    "        self.lr = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "\n",
    "\n",
    "        backbone = torch.hub.load('zhanghang1989/ResNeSt', 'resnest50', pretrained=True)\n",
    "        num_filters = backbone.fc.in_features\n",
    "        layers = list(backbone.children())[:-1]\n",
    "        \n",
    "        self.feature_extractor = nn.Sequential(*layers)\n",
    "\n",
    "        num_target_classes = 800\n",
    "        self.classifier = nn.Linear(num_filters, num_target_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.feature_extractor.eval()\n",
    "        with torch.no_grad():\n",
    "            representations = self.feature_extractor(x).flatten(1)\n",
    "        x = self.classifier(representations)\n",
    "\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "class pre_resnest50_wo_freeze(pl.LightningModule):\n",
    "    def __init__(self, learning_rate, batch_size):\n",
    "        \n",
    "        super(pre_resnest50_wo_freeze, self).__init__()\n",
    "        \n",
    "        self.lr = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        resnest50 = torch.hub.load('zhanghang1989/ResNeSt', 'resnest50', pretrained=True)\n",
    "        trained_resnest50 = pre_resnest50.load_from_checkpoint('pre_resnest50_epoch=54-val_loss=6.26.ckpt', learning_rate=0.08, batch_size=128)\n",
    "\n",
    "        layers_1 = list(resnest50.children())[:-1][0]\n",
    "        layers_2 = list(resnest50.children())[:-1][1:-2]\n",
    "        layers_3 = list(resnest50.children())[:-1][-2:]\n",
    "        self.classifier = list(trained_resnest50.children())[-1]\n",
    "\n",
    "        self.seq_1 = nn.Sequential(*layers_1)\n",
    "        self.seq_2 = nn.Sequential(*layers_2)\n",
    "        self.seq_3 = nn.Sequential(*layers_3)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.seq_1(x)\n",
    "        \n",
    "        self.seq_2.eval()\n",
    "        with torch.no_grad():\n",
    "            x = self.seq_2(x)\n",
    "            \n",
    "        x = self.seq_3(x).flatten(1)    \n",
    "        x = self.classifier(x)\n",
    "\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "class t_brain_right(pl.LightningModule):\n",
    "    def __init__(self, learning_rate, batch_size):\n",
    "        \n",
    "        super(t_brain_right, self).__init__()\n",
    "        \n",
    "        self.lr = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "\n",
    "        tbrain = pre_resnest50_wo_freeze.load_from_checkpoint('resnest50_tbrain_epoch=49-val_loss=0.056.ckpt')\n",
    "\n",
    "        layers_1 = list(tbrain.children())[1]\n",
    "        layers_2 = list(tbrain.children())[2]\n",
    "        layers_3 = list(tbrain.children())[3]\n",
    "        self.classifier = list(tbrain.children())[0]\n",
    "\n",
    "        self.seq_1 = nn.Sequential(*layers_1)\n",
    "        self.seq_2 = nn.Sequential(*layers_2)\n",
    "        self.seq_3 = nn.Sequential(*layers_3)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.seq_1(x)\n",
    "        \n",
    "        self.seq_2.eval()\n",
    "        with torch.no_grad():\n",
    "            x = self.seq_2(x)\n",
    "            \n",
    "        x = self.seq_3(x).flatten(1)    \n",
    "        x = self.classifier(x)\n",
    "\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a361210",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c688c685",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.trainer.supporters import CombinedLoader\n",
    "to_np = lambda x: x.data.cpu().numpy()\n",
    "class t_brain_energy(pl.LightningModule):\n",
    "    def __init__(self, learning_rate, batch_size, m_in ,m_out, temperature):\n",
    "        \n",
    "        super(t_brain_energy, self).__init__()\n",
    "        \n",
    "        self.lr = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.m_in = m_in\n",
    "        self.m_out = m_out\n",
    "        self.temperature = temperature\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "\n",
    "        tbrain = t_brain_right.load_from_checkpoint('resnest50_tbrain_right_epoch=47-val_loss=0.047.ckpt')\n",
    "\n",
    "        layers_1 = list(tbrain.children())[1]\n",
    "        layers_2 = list(tbrain.children())[2]\n",
    "        layers_3 = list(tbrain.children())[3]\n",
    "        self.classifier = list(tbrain.children())[0]\n",
    "\n",
    "        self.seq_1 = nn.Sequential(*layers_1)\n",
    "        self.seq_2 = nn.Sequential(*layers_2)\n",
    "        self.seq_3 = nn.Sequential(*layers_3)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.seq_1(x)\n",
    "        \n",
    "        self.seq_2.eval()\n",
    "        with torch.no_grad():\n",
    "            x = self.seq_2(x)\n",
    "            \n",
    "        x = self.seq_3(x).flatten(1)    \n",
    "\n",
    "        return self.classifier(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        lr_scheduler = {'scheduler': torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma = 0.95),\n",
    "                        'name': 'expo_lr'}\n",
    "        return [optimizer], [lr_scheduler]\n",
    "\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "\n",
    "        train_in_dir = 'C:/Users/bbb50/Desktop/Python/OCR/t_brain_new_gray_augmented/train'\n",
    "        train_out_dir = 'C:/Users/bbb50/Desktop/Python/OCR/ai_free_od_20_aug_train'\n",
    "\n",
    "        data_transform = transforms.Compose([\n",
    "                                    transforms.Resize(size = (224, 224)),\n",
    "                                    transforms.Grayscale(num_output_channels=3),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "        \n",
    "        ds_in = ImageFolder(train_in_dir, transform=data_transform)\n",
    "        ds_out = ImageFolder(train_out_dir, transform=data_transform)\n",
    "        \n",
    "        dl_in = DataLoader(ds_in, batch_size=self.batch_size, shuffle=True)\n",
    "        dl_out = DataLoader(ds_out, batch_size=self.batch_size, shuffle=True)\n",
    "        \n",
    "        \n",
    "        return [dl_in, dl_out]\n",
    "\n",
    "    def training_step(self,batch,batch_idx):\n",
    "        \n",
    "        batch_in = batch[0]\n",
    "        batch_out = batch[1]\n",
    "        \n",
    "        x_in, y_in = batch_in\n",
    "        x_out, _ = batch_out\n",
    "        \n",
    "        data = torch.cat((x_in, x_out), 0)\n",
    "        output = self.forward(data)\n",
    "        output_in = output[:len(x_in)]\n",
    "        output_out = output[len(x_in):]\n",
    "        \n",
    "        logits = F.log_softmax(output_in, dim=1)\n",
    "        ce_loss = F.nll_loss(logits, y_in)\n",
    "        \n",
    "        Ec_out = -torch.logsumexp(output_out, dim=1)\n",
    "        Ec_in = -torch.logsumexp(output_in, dim=1)\n",
    "        energy_loss = (torch.pow(F.relu(Ec_in-self.m_in), 2).mean() + torch.pow(F.relu(self.m_out-Ec_out), 2).mean())\n",
    "        \n",
    "        loss = ce_loss + 0.1*energy_loss\n",
    "\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = accuracy(preds, y_in)\n",
    "\n",
    "        e_score_in = (-to_np((self.temperature*torch.logsumexp(output_in / self.temperature, dim=1)))).mean()\n",
    "        e_score_out = (-to_np((self.temperature*torch.logsumexp(output_out / self.temperature, dim=1)))).mean()\n",
    "        \n",
    "        self.log('train_loss',loss, prog_bar=True , on_step=False, on_epoch=True)\n",
    "        self.log('train_acc', acc, prog_bar=True , on_step=False, on_epoch=True)\n",
    "        self.log('e_score_in', e_score_in, prog_bar=True , on_step=True, on_epoch=True)\n",
    "        self.log('e_score_out', e_score_out, prog_bar=True , on_step=True, on_epoch=True)\n",
    "        return loss\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        \n",
    "        train_in_dir = 'C:/Users/bbb50/Desktop/Python/OCR/t_brain_new_gray_augmented/val'\n",
    "        train_out_dir = 'C:/Users/bbb50/Desktop/Python/OCR/ai_free_od_20_aug_val'\n",
    "    \n",
    "        data_transform = transforms.Compose([\n",
    "                                    transforms.Resize(size = (224, 224)),\n",
    "                                    transforms.Grayscale(num_output_channels=3),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "        \n",
    "        ds_in = ImageFolder(train_in_dir, transform=data_transform)\n",
    "        ds_out = ImageFolder(train_out_dir, transform=data_transform)\n",
    "        \n",
    "        dl_in = DataLoader(ds_in, batch_size=self.batch_size, shuffle=False)\n",
    "        dl_out = DataLoader(ds_out, batch_size=self.batch_size, shuffle=False)\n",
    "        \n",
    "        loaders = {'in': dl_in,'out': dl_out}\n",
    "        combined_loaders = CombinedLoader(loaders, \"max_size_cycle\")\n",
    "        return combined_loaders\n",
    "    \n",
    "    def validation_step(self,batch,batch_idx):\n",
    "        \n",
    "        batch_in = batch['in']\n",
    "        batch_out = batch['out']\n",
    "        \n",
    "        x_in, y_in = batch_in\n",
    "        x_out, _ = batch_out\n",
    "        \n",
    "        data = torch.cat((x_in, x_out), 0)\n",
    "        output = self.forward(data)\n",
    "        output_in = output[:len(x_in)]\n",
    "        output_out = output[len(x_in):]\n",
    "        \n",
    "        logits = F.log_softmax(output_in, dim=1)\n",
    "        ce_loss = F.nll_loss(logits, y_in)\n",
    "        \n",
    "        Ec_out = -torch.logsumexp(output_out, dim=1)\n",
    "        Ec_in = -torch.logsumexp(output_in, dim=1)\n",
    "        energy_loss = (torch.pow(F.relu(Ec_in-self.m_in), 2).mean() + torch.pow(F.relu(self.m_out-Ec_out), 2).mean())\n",
    "        \n",
    "        loss = ce_loss + 0.1*energy_loss\n",
    "\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = accuracy(preds, y_in)\n",
    "        \n",
    "        self.log('val_loss', loss, prog_bar=True , on_step=False, on_epoch=True)\n",
    "        self.log('val_acc', acc, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a802742",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\bbb50/.cache\\torch\\hub\\zhanghang1989_ResNeSt_master\n",
      "Using cache found in C:\\Users\\bbb50/.cache\\torch\\hub\\zhanghang1989_ResNeSt_master\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "t_brain_energy(\n",
       "  (classifier): Linear(in_features=2048, out_features=800, bias=True)\n",
       "  (seq_1): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  )\n",
       "  (seq_2): Sequential(\n",
       "    (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): SplAtConv2d(\n",
       "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "          (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (rsoftmax): rSoftMax()\n",
       "        )\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
       "          (1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): SplAtConv2d(\n",
       "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "          (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (rsoftmax): rSoftMax()\n",
       "        )\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): SplAtConv2d(\n",
       "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "          (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (rsoftmax): rSoftMax()\n",
       "        )\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (avd_layer): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
       "        (conv2): SplAtConv2d(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (rsoftmax): rSoftMax()\n",
       "        )\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "          (1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): SplAtConv2d(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (rsoftmax): rSoftMax()\n",
       "        )\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): SplAtConv2d(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (rsoftmax): rSoftMax()\n",
       "        )\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): SplAtConv2d(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (rsoftmax): rSoftMax()\n",
       "        )\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (avd_layer): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
       "        (conv2): SplAtConv2d(\n",
       "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (rsoftmax): rSoftMax()\n",
       "        )\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "          (1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): SplAtConv2d(\n",
       "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (rsoftmax): rSoftMax()\n",
       "        )\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): SplAtConv2d(\n",
       "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (rsoftmax): rSoftMax()\n",
       "        )\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): SplAtConv2d(\n",
       "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (rsoftmax): rSoftMax()\n",
       "        )\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): SplAtConv2d(\n",
       "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (rsoftmax): rSoftMax()\n",
       "        )\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): SplAtConv2d(\n",
       "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (rsoftmax): rSoftMax()\n",
       "        )\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (seq_3): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (avd_layer): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
       "        (conv2): SplAtConv2d(\n",
       "          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "          (bn0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (rsoftmax): rSoftMax()\n",
       "        )\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "          (1): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): SplAtConv2d(\n",
       "          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "          (bn0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (rsoftmax): rSoftMax()\n",
       "        )\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): SplAtConv2d(\n",
       "          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "          (bn0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (rsoftmax): rSoftMax()\n",
       "        )\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): GlobalAvgPool2d()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = t_brain_energy.load_from_checkpoint('t_brain_energy_epoch=22-val_loss=0.120.ckpt')\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b99d6f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d0062fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "bs = 64\n",
    "\n",
    "ood_dir_1 = 'C:/Users/bbb50/Desktop/Python/OCR/ai_free_od_augmentation_val'\n",
    "ood_dir_2 = 'C:/Users/bbb50/Desktop/Python/OCR/ai_free_od_augmentation_train'\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "                            transforms.Resize(size = (224, 224)),\n",
    "                            transforms.Grayscale(num_output_channels=3),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "ds_ood1 = ImageFolder(ood_dir_1 , transform=data_transform)\n",
    "ds_ood2 = ImageFolder(ood_dir_2, transform=data_transform)\n",
    "\n",
    "dl_ood1 = DataLoader(ds_ood1, batch_size=bs, shuffle=False)\n",
    "dl_ood2 = DataLoader(ds_ood2, batch_size=bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7091248",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dir = 'C:/Users/bbb50/Desktop/Python/OCR/t_brain_new_gray'\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "                            transforms.Resize(size = (224, 224)),\n",
    "                            transforms.Grayscale(num_output_channels=3),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "ds_id = ImageFolder(in_dir , transform=data_transform)\n",
    "\n",
    "dl_id = DataLoader(ds_id, batch_size=bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8c0ff37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n"
     ]
    }
   ],
   "source": [
    "for i, (x, y) in enumerate(dl_id):\n",
    "    print(i)\n",
    "    out = model(x.to(device))\n",
    "    score = -to_np((temperature*torch.logsumexp(out / temperature, dim=1)))\n",
    "    if i == 0:\n",
    "        score_in = score\n",
    "    else:\n",
    "        score_in = np.concatenate((score_in, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "895f93c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: -50.85045\n",
      "2std: -14.469833374023438\n",
      "3std: 3.7204742431640625\n",
      "max 7.7468452\n"
     ]
    }
   ],
   "source": [
    "in_mean = score_in.mean()\n",
    "in_std = np.std(score_in, ddof=1)\n",
    "print('mean:', in_mean)\n",
    "print('2std:', in_mean + 2*in_std)\n",
    "print('3std:', in_mean + 3*in_std)\n",
    "print('max', score_in.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "955041ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.190308"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e021749f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('score_1.npy', score_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "611cb4d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x23ae9ef2ee0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.displot(score_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "40ea4568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 67.93056\n",
      "1std: 37.75620651245117\n",
      "2std: 7.581855773925781\n",
      "3std: -22.59249496459961\n",
      "max -26.177265\n"
     ]
    }
   ],
   "source": [
    "out_mean = score_1.mean()\n",
    "out_std = np.std(score_1, ddof=1)\n",
    "print('mean:', out_mean)\n",
    "print('1std:', out_mean - 1*out_std)\n",
    "print('2std:', out_mean - 2*out_std)\n",
    "print('3std:', out_mean - 3*out_std)\n",
    "print('max', score_1.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c7e49e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number larger than value 0 : 6 | accuracy:0.999905\n",
      "number larger than value 1 : 3 | accuracy:0.999952\n",
      "number larger than value 2 : 3 | accuracy:0.999952\n",
      "number larger than value 3 : 3 | accuracy:0.999952\n",
      "number larger than value 4 : 2 | accuracy:0.999968\n",
      "number larger than value 5 : 2 | accuracy:0.999968\n",
      "number larger than value 6 : 1 | accuracy:0.999984\n",
      "number larger than value 7 : 1 | accuracy:0.999984\n",
      "number larger than value 8 : 0 | accuracy:1.000000\n",
      "number larger than value 9 : 0 | accuracy:1.000000\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    mis_classfied = score_in[score_in > i].shape[0]\n",
    "    print('number larger than value {} : {} | accuracy:{:.6f}'.format(i, mis_classfied, (1-mis_classfied/score_in.shape[0])) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bfc0cd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('max', score_in.max())\n",
    "print('mean', score_in.mean())\n",
    "\n",
    "for i in range(10):\n",
    "    mis_classfied = score_in[score_in > i].shape[0]\n",
    "    print('number larger than value {} : {} | accuracy:{:.6f}'.format(i, mis_classfied, (1-mis_classfied/score_in.shape[0])) )\n",
    "\n",
    "sns.displot(score_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d31e13a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n"
     ]
    }
   ],
   "source": [
    "for i, (x, y) in enumerate(dl_ood1):\n",
    "    print(i)\n",
    "    out = model(x.to(device))\n",
    "    score = -to_np((temperature*torch.logsumexp(out / temperature, dim=1)))\n",
    "    if i == 0:\n",
    "        score_1 = score\n",
    "    else:\n",
    "        score_1 = np.concatenate((score_1, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6503a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc04582",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('mean:', score_out.mean())\n",
    "print('min:', score_out.min())\n",
    "\n",
    "for i in range(-5, 1):\n",
    "    mis_classfied = score_out[score_out < -i].shape[0]\n",
    "    print('number smaller than value {} : {} | accuracy:{:.6f}'.format(-i, mis_classfied, (1-mis_classfied/score_out.shape[0])) )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e3f7f4ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 67.93056\n",
      "min: -26.177265\n"
     ]
    }
   ],
   "source": [
    "print('mean:', score_1.mean())\n",
    "print('min:', score_1.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d5e8449e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number smaller than value 0 : 131 | accuracy:0.996725\n",
      "number smaller than value 1 : 156 | accuracy:0.996100\n",
      "number smaller than value 2 : 180 | accuracy:0.995500\n",
      "number smaller than value 3 : 218 | accuracy:0.994550\n",
      "number smaller than value 4 : 241 | accuracy:0.993975\n",
      "number smaller than value 5 : 277 | accuracy:0.993075\n",
      "number smaller than value 6 : 315 | accuracy:0.992125\n",
      "number smaller than value 7 : 363 | accuracy:0.990925\n",
      "number smaller than value 8 : 415 | accuracy:0.989625\n",
      "number smaller than value 9 : 463 | accuracy:0.988425\n",
      "number smaller than value 10 : 524 | accuracy:0.986900\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    mis_classfied = score_1[score_1 < i].shape[0]\n",
    "    print('number smaller than value {} : {} | accuracy:{:.6f}'.format(i, mis_classfied, (1-mis_classfied/score_1.shape[0])) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "45834854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number smaller than value 0 : 813 | accuracy:0.979674\n",
      "number smaller than value 1 : 937 | accuracy:0.976574\n",
      "number smaller than value 2 : 1072 | accuracy:0.973199\n",
      "number smaller than value 3 : 1239 | accuracy:0.969024\n",
      "number smaller than value 4 : 1442 | accuracy:0.963949\n",
      "number smaller than value 5 : 1657 | accuracy:0.958574\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    mis_classfied = score_1[score_1 < i].shape[0]\n",
    "    print('number smaller than value {} : {} | accuracy:{:.6f}'.format(i, mis_classfied, (1-mis_classfied/score_1.shape[0])) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7086db45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x23ae9f473a0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.displot(score_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5082968c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i, (x, y) in enumerate(dl_ood2):\n",
    "    print(i)\n",
    "    out = model(x.to(device))\n",
    "    score = -to_np((temperature*torch.logsumexp(out / temperature, dim=1)))\n",
    "    if i == 0:\n",
    "        score_2 = score\n",
    "    else:\n",
    "        score_2 = np.concatenate((score_2, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5a287db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# np.save('score_1.npy', score_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "38659b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('mean:', score_out.mean())\n",
    "# print('min:', score_out.min())\n",
    "\n",
    "# for i in range(-5, 1):\n",
    "#     mis_classfied = score_out[score_out < -i].shape[0]\n",
    "#     print('number smaller than value {} : {} | accuracy:{:.6f}'.format(-i, mis_classfied, (1-mis_classfied/score_out.shape[0])) )\n",
    "    \n",
    "# sns.displot(score_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a540fb77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0748563f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\bbb50/.cache\\torch\\hub\\zhanghang1989_ResNeSt_master\n",
      "Using cache found in C:\\Users\\bbb50/.cache\\torch\\hub\\zhanghang1989_ResNeSt_master\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "model = t_brain_energy(0.058, 32, -5, -21, 1)\n",
    "lr_logger = LearningRateMonitor()\n",
    "\n",
    "logger = TensorBoardLogger(\"t_brain_energy\", name=\"t_brain_energy\")\n",
    "\n",
    "early_stopping = EarlyStopping('val_loss', mode='min', patience=5)\n",
    "\n",
    "model_path = 'C:/Users/bbb50/Desktop/Python/OCR/model_path/t_brain_energy'\n",
    "checkpoint_callback = ModelCheckpoint(dirpath=model_path, filename= 't_brain_energy_{epoch}-{val_loss:.3f}',\n",
    "                                      monitor='val_loss', mode='min', save_top_k=5)\n",
    "\n",
    "trainer = pl.Trainer(resume_from_checkpoint='t_brain_energy_epoch=10-val_loss=0.215.ckpt',  gpus=1, limit_train_batches=0.2 ,max_epochs=100, callbacks=[lr_logger, early_stopping, checkpoint_callback], logger=logger,\n",
    "       ) #gpus=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "363595fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type       | Params\n",
      "------------------------------------------\n",
      "0 | classifier | Linear     | 1.6 M \n",
      "1 | seq_1      | Sequential | 28.6 K\n",
      "2 | seq_2      | Sequential | 9.3 M \n",
      "3 | seq_3      | Sequential | 16.2 M\n",
      "------------------------------------------\n",
      "27.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "27.1 M    Total params\n",
      "108.294   Total estimated model params size (MB)\n",
      "Restored states from the checkpoint file at t_brain_energy_epoch=10-val_loss=0.215.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae4c18193ec340dbba75b9182b5bdf04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
